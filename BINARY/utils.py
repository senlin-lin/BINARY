import pandas as pd
import numpy as np
import sklearn.neighbors
import scipy.sparse as sp
import seaborn as sns
import matplotlib.pyplot as plt
import ot
import scanpy as sc
import torch
from torch_geometric.data import Data
import anndata as ad


def Count2Binary(adata):
    """
    Convert raw count data to binary format (0 or 1) in an AnnData object.

    Parameters:
    adata : AnnData
        The input AnnData object containing the matrix of raw counts. The matrix
        should be accessible via `adata.X`. This matrix should be numerical.

    Returns:
    AnnData
        The modified AnnData object where the original raw count matrix is
        replaced with a binary matrix. In this binary matrix, any non-zero value
        in the original data is set to 1, and zero values remain zero.

    Example:
    >>> adata = AnnData(np.array([[0, 2], [3, 0], [1, 1]]))
    >>> Count2Binary(adata)
    >>> print(adata.X)
    array([[0., 1.],
           [1., 0.],
           [1., 1.]])
    """
    # Convert raw count data to binary by checking if each element is greater than 0.
    # If true, the value becomes 1 (converted to float64). If false, remains 0.
    adata.X = (adata.X > 0).astype(np.float64)
    return adata



def Multi_Refine_label(adata, radius=30, key='mclust', add_key='refine_label', obs_key='slice_id'):
    """
    Refine labels for each unique section in an AnnData object by calling the Refine_label function.

    Parameters:
    adata : AnnData
        The input AnnData object containing the data and labels to be refined.

    radius : int, optional (default=30)
        The number of neighboring cells used to refine the labels in the Refine_label function.

    key : str, optional (default='mclust')
        The key in adata.obs used to access the old labels that need to be refined.

    add_key : str, optional (default='refine_label')
        The key in adata.obs where the refined labels will be stored.

    obs_key : str, optional (default='slice_id')
        The key in adata.obs used to access unique sections.

    Returns:
    AnnData
        The modified AnnData object with refined labels.

    """
    unique_sections = adata.obs[obs_key].unique()
    for section in unique_sections:
        section_data = adata[adata.obs[obs_key] == section].copy()
        refined_labels = Refine_label(section_data, radius=radius, key=key)
        adata.obs.loc[adata.obs[obs_key] == section, add_key] = refined_labels
    return adata


def Refine_label(adata, radius=30, key='label'):
    """
    Refine cell labels based on their spatial neighbors' labels.

    Parameters:
    adata : AnnData
        The input AnnData object containing the data and labels to be refined.

    radius : int, optional (default=30)
        The number of neighboring cells used for refining the label of each cell.

    key : str, optional (default='label')
        The key in adata.obs used to access the old labels that need to be refined.

    Returns:
    list
        A list of refined labels as strings.

    """
    n_neigh = radius
    new_type = []
    old_type = adata.obs[key].values
    
    #calculate distance
    position = adata.obsm['spatial']
    distance = ot.dist(position, position, metric='euclidean')
           
    n_cell = distance.shape[0]
    
    for i in range(n_cell):
        vec  = distance[i, :]
        index = vec.argsort()
        neigh_type = []
        for j in range(1, n_neigh+1):
            neigh_type.append(old_type[index[j]])
        max_type = max(neigh_type, key=neigh_type.count)
        new_type.append(max_type)
        
    new_type = [str(i) for i in list(new_type)]    
    return new_type


def find_optimal_resolution(adata, desired_clusters, algorithm="leiden", add_key=None, start=0, end=5, step=1, max_iter=50):
    """
    Find the optimal resolution using a binary search method.
    
    Parameters:
        adata: AnnData object
        desired_clusters: Desired number of clusters
        algorithm: Clustering algorithm, choose between 'leiden' or 'louvain'
        add_key: Key used to store clustering results in adata.obs
        start: Starting resolution
        end: Ending resolution
        step: Step size to adjust resolution
        max_iter: Maximum number of iterations
        
    Returns:
        best_resolution: The optimal resolution
    """
    
    if algorithm not in ["leiden", "louvain"]:
        raise ValueError("Invalid algorithm choice. Choose 'leiden' or 'louvain'")
    
    if add_key is None:
        add_key = algorithm
    
    iteration = 0
    
    while iteration < max_iter:
        midpoint = (start + end) / 2
        
        if algorithm == "leiden":
            sc.tl.leiden(adata, resolution=midpoint, key_added=add_key)
        else:
            sc.tl.louvain(adata, resolution=midpoint, key_added=add_key)
        
        num_clusters = len(np.unique(adata.obs[add_key]))
        
        if num_clusters == desired_clusters:
            print(f"The optimal resolution is: {midpoint}")
            print(f"Stored in adata.obs[{add_key}]:", add_key)
            return midpoint
        elif num_clusters < desired_clusters:
            start = midpoint
        else:
            end = midpoint
            
        step = step / 2
        iteration += 1
        
    print("The optimal resolution was not found within the given number of iterations.")
    print("Try to fine-tune the start and end values.")


def Transfer_pytorch_Data(adata):
    """
    Convert an AnnData object to a PyTorch-Geometric Data object, incorporating spatial relationships.

    Returns:
    
    A PyTorch-Geometric Data object with the edge_index representing the 
    spatial relationships between cells and x representing the expression data.

    """
    G_df = adata.uns['Spatial_Graph'].copy()
    cells = np.array(adata.obs_names)
    cells_id_tran = dict(zip(cells, range(cells.shape[0])))
    G_df['Cell_i'] = G_df['Cell_i'].map(cells_id_tran)
    G_df['Cell_j'] = G_df['Cell_j'].map(cells_id_tran)

    G = sp.coo_matrix((np.ones(G_df.shape[0]), (G_df['Cell_i'], G_df['Cell_j'])), shape=(adata.n_obs, adata.n_obs))
    G = G + sp.eye(G.shape[0])

    edgeList = np.nonzero(G)
    if type(adata.X) == np.ndarray:
        data = Data(edge_index=torch.LongTensor(np.array(
            [edgeList[0], edgeList[1]])), x=torch.FloatTensor(adata.X))  # .todense()
    else:
        data = Data(edge_index=torch.LongTensor(np.array(
            [edgeList[0], edgeList[1]])), x=torch.FloatTensor(adata.X.todense()))  # .todense()
    return data


def Construct_Spatial_Graph(adata, use_method='KNN', cutoff = None):
    """
    Construct a spatial graph based on either K-Nearest Neighbors (KNN) or a fixed radius.

    Parameters:
    adata : AnnData
        The input AnnData object containing spatial coordinates in the obsm['spatial'] attribute.

    use_method : str (default='KNN')
        The method used to construct the spatial graph. 
        Acceptable values: 'KNN' or 'Radius'.

    cutoff : int
        For 'KNN' method, it determines the number of nearest neighbors.
        For 'Radius' method, it determines the distance threshold for considering neighbors.

    Returns:
    None
        Modifies the input adata object to include a 'Spatial_Graph' uns attribute containing the spatial graph.
    """
    
    assert(use_method in ['Radius', 'KNN'])
    print('------Constructing spatial graph...------')
    coor = pd.DataFrame(adata.obsm['spatial'])
    coor.index = adata.obs.index
    coor.columns = ['imagerow', 'imagecol']

    if use_method == 'KNN':
        nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=cutoff+1).fit(coor)
        distances, indices = nbrs.kneighbors(coor)
        KNN_list = []
        for it in range(indices.shape[0]):
            KNN_list.append(pd.DataFrame(zip([it]*indices.shape[1],indices[it,:], distances[it,:])))
    
    if use_method == 'Radius':
        nbrs = sklearn.neighbors.NearestNeighbors(radius=cutoff).fit(coor)
        distances, indices = nbrs.radius_neighbors(coor, return_distance=True)
        KNN_list = []
        for it in range(indices.shape[0]):
            KNN_list.append(pd.DataFrame(zip([it]*indices[it].shape[0], indices[it], distances[it])))
            
    KNN_df = pd.concat(KNN_list)
    KNN_df.columns = ['Cell_i', 'Cell_j', 'Distance']

    Spatial_Graph = KNN_df.copy()
    Spatial_Graph = Spatial_Graph.loc[Spatial_Graph['Distance']>0,]
    id_cell_trans = dict(zip(range(coor.shape[0]), np.array(coor.index), ))
    Spatial_Graph['Cell_i'] = Spatial_Graph['Cell_i'].map(id_cell_trans)
    Spatial_Graph['Cell_j'] = Spatial_Graph['Cell_j'].map(id_cell_trans)
    print('The graph contains %d edges, %d cells.' %(Spatial_Graph.shape[0], adata.n_obs))
    print('%.4f neighbors per cell on average.' %(Spatial_Graph.shape[0]/adata.n_obs))

    adata.uns['Spatial_Graph'] = Spatial_Graph
    
    if use_method == 'Radius':
        Stats_Spatial_Graph(adata)



def Mutil_Construct_Spatial_Graph(adata, use_method='KNN', cutoff=None, obs_key=None, use_list=None):
    """
    Construct spatial graphs for either all or a subset of values in adata.obs[obs_key].

    Parameters:
    adata : AnnData
        The input AnnData object containing spatial coordinates in the obsm['spatial'] attribute.

    use_method : str (default='KNN')
        The method used to construct the spatial graph.
        Acceptable values: 'KNN' or 'Radius'.

    cutoff : int
        For 'KNN' method, it determines the number of nearest neighbors.
        For 'Radius' method, it determines the distance threshold for considering neighbors.

    obs_key : str
        The key in adata.obs used to access unique values.

    use_list : list or None (default=None)
        A list of specific values in adata.obs[obs_key] to be processed.
        If None, all unique values in adata.obs[obs_key] will be processed.

    Returns:
    AnnData
        A modified AnnData object with a 'Spatial_Graph' uns attribute containing the combined spatial graphs.
    """
    
    if use_list is None:
        # Process all unique values in adata.obs[obs_key]
        all_values = adata.obs[obs_key].unique()
        all_nets = []  # Store individual Spatial_Graph DataFrames
        for value in all_values:
            #temp_adata = adata.loc[adata.obs[obs_key] == value, :].copy()
            temp_adata = adata[adata.obs[obs_key] == value].copy()
            Construct_Spatial_Graph(temp_adata, use_method=use_method, cutoff=cutoff)
            all_nets.append(temp_adata.uns['Spatial_Graph'])
        
        # Combine all Spatial_Graph DataFrames
        combined_net = pd.concat(all_nets)
        adata.uns['Spatial_Graph'] = combined_net

    else:
        # Process a subset of values defined by use_list
        selected_values = set(use_list)
        selected_nets = []  # Store individual Spatial_Graph DataFrames
        for value in selected_values:
            temp_adata = adata[adata.obs[obs_key] == value].copy()
            Construct_Spatial_Graph(temp_adata, use_method=use_method, cutoff=cutoff)
            selected_nets.append(temp_adata.uns['Spatial_Graph'])
        
        # Combine selected Spatial_Graph DataFrames
        combined_net = pd.concat(selected_nets)
        adata.uns['Spatial_Graph'] = combined_net
        
        # Only keep rows in adata where adata.obs[obs_key] is in use_list
        adata = adata[adata.obs[obs_key].isin(use_list)].copy()
    
    return adata

def concat_adatas(adatas, section_list):
    """
    Process and store a list of AnnData objects in a dictionary.

    Parameters:
        adatas (list): List of AnnData objects.
        section_list (list): List of section IDs.

    Returns:
        dict: Dictionary containing processed AnnData objects.
    """
    
    if len(adatas) != len(section_list):
        raise ValueError("Length of adatas and section_list should be the same.")

    adata_list = {}

    for idx, (adata, section_id) in enumerate(zip(adatas, section_list)):
        # Add slice_id to obs using section_id
        adata.obs['slice_id'] = section_id

        # Make the spot name unique
        adata.obs_names = [f"{x}_{section_id}" for x in adata.obs_names]

        # Store the processed adata in the dictionary
        adata_list[section_id] = adata.copy()

    return adata_list

def merge_adatas(adatas, slice_keys):
    """
    Merge multiple AnnData objects, capturing and merging 'var' and 'uns' information present in any given object.
    
    Parameters:
        adatas (list): List of AnnData objects
        slice_keys (list): List of keys to mark each AnnData object

    Returns:
        AnnData: Merged AnnData object
    """
    if len(adatas) != len(slice_keys):
        raise ValueError("Length of adatas and section_list should be the same.")
    
    # Add 'slice_id' to the obs of each AnnData object using the provided slice_keys
    for adata, slice_key in zip(adatas, slice_keys):
        adata.obs['slice_id'] = slice_key
    
    # Use the concatenate function to merge all AnnData objects
    merged_adata = sc.concat(adatas)
    """
    # Merge 'var' attributes
    for adata in adatas:
        if hasattr(adata, 'var') and not adata.var.empty:
            for key, value in adata.var.items():
                if key not in merged_adata.var:
                    merged_adata.var[key] = value
                    
    # Merge 'uns' attributes
    for adata in adatas:
        if hasattr(adata, 'uns') and adata.uns:
            for key, value in adata.uns.items():
                if key not in merged_adata.uns:
                    merged_adata.uns[key] = value
    """
    return merged_adata


def clean_adata(adata_raw, save_obs=[]):
    """
    Clean the input AnnData object by retaining only specific attributes.
    
    Parameters:
        adata_raw (AnnData): The original AnnData object to be cleaned.
        save_obs (list, optional): A list of keys for the obs attributes to retain.
        
    Returns:
        AnnData: Cleaned AnnData object.
    """
    
    # Extract required attributes
    X = adata_raw.X
    var_names = adata_raw.var_names
    obs_names = adata_raw.obs_names
    spatial = adata_raw.obsm['spatial']
    
    # Create a new AnnData object
    adata_cleaned = ad.AnnData(X)
    adata_cleaned.var_names = var_names
    adata_cleaned.obs_names = obs_names
    adata_cleaned.obsm['spatial'] = spatial
    
    # Retain the obs attributes specified by save_obs
    for key in save_obs:
        if key in adata_raw.obs:
            adata_cleaned.obs[key] = adata_raw.obs[key]
    
    # Preserve 'spatial' key in uns if it exists
    if 'spatial' in adata_raw.uns:
        adata_cleaned.uns['spatial'] = adata_raw.uns['spatial']
        
    return adata_cleaned


def Stats_Spatial_Graph(adata):
    import matplotlib.pyplot as plt
    import pandas as pd
    
    # Existing calculations
    Num_edge = adata.uns['Spatial_Graph']['Cell_i'].shape[0]
    Mean_edge = Num_edge/adata.shape[0]
    plot_df = pd.value_counts(pd.value_counts(adata.uns['Spatial_Graph']['Cell_i']))
    plot_df = plot_df/adata.shape[0]
    
    # Setting up the figure and axis
    fig, ax = plt.subplots(figsize=[5, 4]) # Increase figure size for better readability
    bars = ax.bar(plot_df.index, plot_df, color='skyblue') # Using a softer color
    
    # Adding data values on top of the bars
    for bar in bars:
        yval = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, yval + 0.005, round(yval, 2), ha='center', va='bottom')
    
    # Enhancing axis labels and title
    plt.ylabel('Percentage', fontsize=12, fontweight='bold')
    plt.xlabel('Number of Neighbors', fontsize=12, fontweight='bold')
    plt.title('Number of Neighbors (Mean=%.2f)' % Mean_edge, fontsize=14, fontweight='bold')
    
    # Adjusting aesthetics
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    ax.spines['top'].set_visible(False) # Hide top border
    ax.spines['right'].set_visible(False) # Hide right border
    
    plt.tight_layout()
    plt.show()
"""
def Stats_Spatial_Graph(adata):
    import matplotlib.pyplot as plt
    Num_edge = adata.uns['Spatial_Graph']['Cell_i'].shape[0]
    Mean_edge = Num_edge/adata.shape[0]
    plot_df = pd.value_counts(pd.value_counts(adata.uns['Spatial_Graph']['Cell_i']))
    plot_df = plot_df/adata.shape[0]
    fig, ax = plt.subplots(figsize=[3,2])
    plt.ylabel('Percentage')
    plt.xlabel('')
    plt.title('Number of Neighbors (Mean=%.2f)'%Mean_edge)
    ax.bar(plot_df.index, plot_df)
    
"""

def mclust_R(adata, num_cluster, add_key = 'mclust', modelNames='EEE', used_obsm='BINARY', random_seed=2020):
    """
    Cluster an AnnData object using the mclust algorithm from R.
    
    Parameters:
    ----------
    adata : AnnData
        The AnnData object containing the data to be clustered.
        
    num_cluster : int
        The number of clusters to be constructed.
        
    add_key : str, optional (default='mclust')
        The key added to `adata.obs` to store the cluster results.
        
    modelNames : str, optional (default='EEE')
        The parameter for the Mclust method in R specifying the model to be used for clustering. 
        For details on the possible models, refer to the mclust documentation.
        
    used_obsm : str, optional (default='BINARY')
        The key in `adata.obsm` that refers to the data matrix used for clustering.
        
    random_seed : int, optional (default=2020)
        The random seed for reproducibility.
        
    Returns:
    -------
    AnnData
        The input AnnData object with added clustering results in `adata.obs[add_key]`.
    """
    
    np.random.seed(random_seed)
    import rpy2.robjects as robjects
    robjects.r.library("mclust")

    import rpy2.robjects.numpy2ri
    rpy2.robjects.numpy2ri.activate()
    r_random_seed = robjects.r['set.seed']
    r_random_seed(random_seed)
    rmclust = robjects.r['Mclust']

    res = rmclust(rpy2.robjects.numpy2ri.numpy2rpy(adata.obsm[used_obsm]), num_cluster, modelNames)
    mclust_res = np.array(res[-2])

    adata.obs[add_key] = mclust_res
    adata.obs[add_key] = adata.obs[add_key].astype('int')
    adata.obs[add_key] = adata.obs[add_key].astype('category')
    return adata
